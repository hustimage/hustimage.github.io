<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>图像分析与理解 by hustimage</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">图像分析与理解</h1>
      <h2 class="project-tagline">华中科技大学《图像分析与理解》课程项目进度汇报</h2>
    </section>

    <section class="main-content">
      <h1>
<a id="项目名称3d-rigid-object-tracking" class="anchor" href="#%E9%A1%B9%E7%9B%AE%E5%90%8D%E7%A7%B03d-rigid-object-tracking" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>项目名称：3D Rigid Object Tracking</h1>

<h2>
<a id="小组成员巨荣辉谢存煌柯旺松张兴龙" class="anchor" href="#%E5%B0%8F%E7%BB%84%E6%88%90%E5%91%98%E5%B7%A8%E8%8D%A3%E8%BE%89%E8%B0%A2%E5%AD%98%E7%85%8C%E6%9F%AF%E6%97%BA%E6%9D%BE%E5%BC%A0%E5%85%B4%E9%BE%99" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>小组成员：巨荣辉、谢存煌、柯旺松、张兴龙</h2>



<h3>
<a id="2016年5月19日更新" class="anchor" href="#2016%E5%B9%B45%E6%9C%8819%E6%97%A5%E6%9B%B4%E6%96%B0" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2016年5月19日更新</h3>

<p>选择项目3D Rigid Object Tracking，项目开始。</p>

<h3>
<a id="2016年5月26日更新" class="anchor" href="#2016%E5%B9%B45%E6%9C%8826%E6%97%A5%E6%9B%B4%E6%96%B0" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2016年5月26日更新：</h3>

<ul>
<li><p>. 阅读项目中所给文献，了解本项目所需关键技术；</p></li>
<li><p>. 组内成员对matlab较为熟悉，暂定其作为编程平台完成相关内容，后期如有需要再移植至其他平台；</p></li>
<li>
<p>. 因为3D Rigid Object Tracking 需要调动摄像头进行相关图像处理内容，完成简单的matlab摄像头调用代码。</p>

<p><code>clear all; clc</code></p>

<p><code>vid = videoinput('winvideo', 1, 'YUY2_640x480');%创建ID为1的摄像头的视频对象</code></p>

<p><code>set(vid,'ReturnedColorSpace','rgb');</code></p>

<p><code>vidRes=get(vid,'VideoResolution');</code></p>

<p><code>width=vidRes(1);</code></p>

<p><code>height=vidRes(2);</code></p>

<p><code>nBands=get(vid,'NumberOfBands');</code></p>

<p><code>figure('Name', 'Matlab调用摄像头 ', 'NumberTitle', 'Off', 'ToolBar', 'None', 'MenuBar', 'None');</code></p>

<p><code>hImage=image(zeros(vidRes(2),vidRes(1),nBands));</code></p>

<p><code>preview(vid,hImage);    %打开视频预览窗口</code></p>
</li>
</ul>

<p><img src="http://i4.buimg.com/eca3297b1e2722a3.png" alt="matlab调用摄像头">
（不知道如何插入视频=_=）</p>

<ul>
<li>. matlab调用摄像头成功之后，通过对每一帧进行解析，进行简单的图像处理操作，通过帧差的方法实现简单的物体跟踪，当然不是很稳定，后期进行改  进。通过帧差方法可以得到大致的运动物体所在区域，为后期工作中特征匹配的实现奠定一个基础，如图是实现的效果（视频不知道怎么插入=_=）。</li>
</ul>

<p><img src="http://i2.buimg.com/8f51be16b9025a4a.png" alt="简单物体识别"></p>

<ul>
<li>. 后续需要进行的工作包括物体特征的提取，视频实时的物体匹配识别，AR实现等。
（本次更新到此为止）</li>
</ul>

<h3>
<a id="2016年6月2日更新" class="anchor" href="#2016%E5%B9%B46%E6%9C%882%E6%97%A5%E6%9B%B4%E6%96%B0" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2016年6月2日更新：</h3>

<ul>
<li><p>. 为了更好地了解项目的相关知识，我们选择了2篇文献去学习；</p></li>
<li><p>. 我们主要阅读了《Keyframe-based Modeling and Tracking of Multiple 3D Objects》这篇文献：</p></li>
</ul>

<p>本文主要提出了一种实现了检测和帧到帧的追踪的对多个3D物体进行追踪的算法。该方法的主要缺点是，随着图像内超过10个物体时，它在计算时间和数据存储方面大大增加，从而变得不切实际。</p>

<p>对于一个给定的输入帧，检测模块返回由相似性得分排序的关键帧的列表。我们认为每个物体至少有一个关键帧数据库。如果一个物体比另一个展示出更多的得分点，它往往会人为地得到更好的得分，并且在最好的关键帧更频繁地出现。然后，通过采用RANSAC计算目标pose，我们尝试强每个关键帧与输入图像匹配。</p>

<p><img src="http://7xrn7f.com1.z0.glb.clouddn.com/16-6-2/1895005.jpg" alt="论文中出现的结果1"></p>

<p><img src="http://7xrn7f.com1.z0.glb.clouddn.com/16-6-2/84021982.jpg" alt="论文中出现的结果2"></p>

<p>（a）系统连续地重建环境和从视频中跟踪相机流；
（b）在添加新的物体时，用户通过使用刷状工具选择物体的某些功能；
（c）系统可以调整展示的平面信息
（d）扩展到三维框
（e）（f）物体可以在场景内随意的移动
（g-k）已知的物体当它们被看到时就可被识别，并且被独立的追踪</p>

<ul>
<li>. 接下来的一周需要我们通过文献中学到的算法，从而来实现整个项目
（本次更新到此为止）</li>
</ul>

<h3>
<a id="2016年6月9日更新" class="anchor" href="#2016%E5%B9%B46%E6%9C%889%E6%97%A5%E6%9B%B4%E6%96%B0" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2016年6月9日更新：</h3>

<ul>
<li>. 通过之前两周的文献阅读和先期工作，我们确定了项目所使用的主要方法：</li>
</ul>

<p>使用Camshift算法来实现对物体的追踪，并使用卡尔曼滤波来预测物体接下来的位置以防止出现遮挡的情况。</p>

<ul>
<li>. camshift算法</li>
</ul>

<p>camshift利用目标的颜色直方图模型将图像转换为颜色概率分布图，初始化一个搜索窗的大小和位置，并根据上一帧得到的结果自适应调整搜索窗口的位置和大小，从而定位出当前图像中目标的中心位置。</p>

<p>色彩投影图（反向投影）：(1).RGB颜色空间对光照亮度变化较为敏感，为了减少此变化对跟踪效果的影响，首先将图像从RGB空间转换到HSV空间。(2).然后对其中的H分量作直方图，在直方图中代表了不同H分量值出现的概率或者像素个数，就是说可以查找出H分量大小为h的概率或者像素个数，即得到了颜色概率查找表。(3).将图像中每个像素的值用其颜色出现的概率对替换，就得到了颜色概率分布图。这个过程就叫反向投影，颜色概率分布图是一个灰度图像。</p>

<p>camshift：将meanshift算法扩展到连续图像序列，就是camshift算法。它将视频的所有帧做meanshift运算，并将上一帧的结果，即搜索窗的大小和中心，作为下一帧meanshift算法搜索窗的初始值。如此迭代下去，就可以实现对目标的跟踪。</p>

<p>算法过程为：
(1).初始化搜索窗
(2).计算搜索窗的颜色概率分布（反向投影）
(3).运行meanshift算法，获得搜索窗新的大小和位置。
(4).在下一帧视频图像中用(3)中的值重新初始化搜索窗的大小和位置，再跳转到(2)继续进行。</p>

<ul>
<li><p>. 对于物体的追踪，如果背景单一，即你要跟踪的物体颜色和背景色有较大区别，可用基于颜色的跟踪如camshift，鲁棒性都是较好的；如果背景复杂,如背景中有和前景一样的颜色，就需要用到一些具有预测性的算法，如卡尔曼滤波等，可以和CAMSHIFT结合。</p></li>
<li><p>. 所以接下来的一周我们将会根据以上算法来实现项目的内容。
（本次更新到此为止）</p></li>
</ul>

<h3>
<a id="2016年6月16日更新" class="anchor" href="#2016%E5%B9%B46%E6%9C%8816%E6%97%A5%E6%9B%B4%E6%96%B0" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2016年6月16日更新：</h3>

<ul>
<li>. 本周是项目的最后一周，我们也会在这次更新中展示出项目的demo，下面会给出相应的演示视频。</li>
</ul>

<p><img src="http://7xrn7f.com1.z0.glb.clouddn.com/16-6-18/6949119.jpg" alt="项目效果图"></p>

<p>效果图中，我们用蓝色边框将物体框出，并不断地对其进行追踪，而图中的绿色小×代表了用camshift算法得到的物体的质心，粉红色的小×代表了卡尔曼滤波得到的预测的质心。具体的更多细节可参见本次更新最后的demo视频。</p>

<ul>
<li>. 环境配置：OpenCV3.1<br>
Visual Studio 2013<br>
Windows 10 64位系统</li>
</ul>

<p>图像分析与理解课程项目演示视频:</p>

<h1></h1>

<p>目标跟踪速度： &gt;30 FPS</p>

<p>（本次更新到此为止）</p>

      <footer class="site-footer">

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
